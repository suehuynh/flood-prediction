{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/suehuynh/flood-prediction-eda-xgboost-ensemble?scriptVersionId=180634669\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Flood Prediction - Kaggle Playground May 2024\n\nGoal: The goal of this competition is to predict the probability of a region flooding based on various factors.","metadata":{}},{"cell_type":"markdown","source":"# Preparation\n### Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd              # For data manipulation and analysis\nimport numpy as np               # For numerical computing\nfrom datetime import datetime\nimport scipy.stats as stats      # For statistical analysis\nimport math\nimport matplotlib                # For plotting and visualization\nimport matplotlib.pyplot as plt  \nfrom pandas.plotting import parallel_coordinates\nimport seaborn as sns            # For statistical data visualization\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-30T15:51:48.476323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load datasets","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e5/train.csv',index_col=0)\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e5/test.csv', index_col=0)\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s4e5/sample_submission.csv',index_col=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n- Train dataset has 1,117,957 rows x 21 columns, of 20 predictors and FloodProbability being the target for the model.\n- Test dataset has 745,305 rows x 21 columns of 20 predictors and 1 ID column.\n- Both datasets are very structured and 'clean' with no missing values.\n- All the predictors are numerical and specifically, integers.\n","metadata":{}},{"cell_type":"code","source":"df_train.describe().T.style","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization\n### Univariate Analysis\nFirst, let's look at the distribution of each predictor.","metadata":{}},{"cell_type":"code","source":"sns.histplot(data = df_train['FloodProbability'], bins = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 4, figsize=(20, 25))\n \nfor i, column in enumerate(df_train.columns):\n    if column == 'FloodProbability':\n        continue\n    plt.subplots_adjust(top = 0.85)\n    ax = sns.histplot(data = df_train, \n                x = column, \n                bins = df_train[column].nunique(),\n                ax = axes[i // 4, i % 4])\n    \n    ax.set_yticklabels(['{:,.0f}K'.format(ticks / 1000) for ticks in ax.get_yticks()])\nfig.tight_layout(h_pad = 2)\nplt.subplots_adjust(top = 0.95)\nplt.suptitle('Distribution of Flood Predictors', fontsize = 14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: The predictors are slightly right-skew normally distributed with the mean around 4.0 to 6.0.","metadata":{}},{"cell_type":"markdown","source":"### Multivariate Analysis\nNext, let's examine the correlation of predictor-to-predictor and predictor-to-target using correlation heatmap.","metadata":{}},{"cell_type":"code","source":"# Correlation Matrix Heatmap\nfig, ax = plt.subplots(figsize = (12,10))\ncorr = df_train.corr()\nhm = sns.heatmap(corr,\n                annot = True,\n                ax = ax,\n                cmap = 'Blues',\n                fmt = '.2f')\nfig.subplots_adjust(top = 0.95)\nplt.suptitle('Flood Predictors Correlation Heatmap', fontsize = 14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n- There are very low correlation among the predictors, showing their independence in the model. We will not need to remove any of them!\n- Each predictor has the similar correlation with the target at around 0.18 to 0.19.\n\n**Actions:**\n- Visualize the relationship of each predictor-to-target pairs to uncover patterns using scatterplots.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 4, figsize=(20, 25))\n\nfor i, column in enumerate(df_train.columns):\n    if column == 'FloodProbability':\n        continue\n    temp_df = df_train[['FloodProbability', column]].groupby(column).mean().reset_index()\n    plt.subplots_adjust(top = 0.85)\n    ax = sns.scatterplot(data = temp_df,\n                y = column,\n                x = 'FloodProbability',\n                ax = axes[i // 4, i % 4])\n\nfig.tight_layout(h_pad = 2)\nfig.subplots_adjust(top = 0.97)\nplt.suptitle('Linearity between each of Predictors and Flood Probability', fontsize = 14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations** - There is a **strong linear relationship** between each predictor to the target. The `FloodProbability` tends to increase as the predictor increases in their values. Hence, Linear Regression might be a good candidate for the prediction.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering\n**Credit to**\n- https://www.kaggle.com/code/trupologhelper/ps4e5-openfe-blending-explain\n\nEach newly created feature represents a combination or interaction between the original features, which can be more informative for predicting the likelihood of floods. Here's an explanation of each new feature:\n\n- 'total': The sum of all original features for each data row. 📈\n- 'mean': The average value of the original features for each data row. 🌡️\n- 'std': The standard deviation of the original features for each data row. 📏\n- 'max': The maximum value among the original features for each data row. 📈\n- 'min': The minimum value among the original features for each data row. 📉\n- 'median': The median of the original features for each data row. 📊\n- 'ptp': The range (difference between the maximum and minimum values) of the original features for each data row. 📏\n- 'q25': The 25th percentile (first quartile) of the original features for each data row. 📊\n- 'q75': The 75th percentile (third quartile) of the original features for each data row. 📊\n- 'ClimateImpact': The sum of monsoon intensity and climate change, indicating the overall impact of climatic factors. 🌍\n- 'AnthropogenicPressure': The sum of deforestation, urbanization, agricultural practices, and encroachments, representing anthropogenic pressure on the environment. 🏭\n- 'InfrastructureQuality': The sum of dam quality, drainage systems, and deteriorating infrastructure, indicating the overall quality of infrastructure. 🏗️\n- 'CoastalVulnerabilityTotal': The sum of coastal vulnerability and landslides, representing the total vulnerability of coastal areas. 🌊\n- 'PreventiveMeasuresEfficiency': The sum of river management, ineffective disaster preparedness, and inadequate planning, indicating the effectiveness of preventive measures. 🚧\n- 'EcosystemImpact': The sum of wetland loss and watersheds, representing the impact on ecosystems. 🌿\n- 'SocioPoliticalContext': The product of population assessment and political factors, indicating the socio-political context. 👥\n- 'FloodVulnerabilityIndex': The average sum of anthropogenic pressure, infrastructure quality, total coastal vulnerability, and preventive measures efficiency, representing the flood vulnerability index. 🌊\n- 'PopulationDensityImpact': The product of population assessment, urbanization, and encroachments, indicating the impact of population density. 👨‍👩‍👧‍👦\n- 'DeforestationUrbanizationRatio': The ratio of deforestation to urbanization. 🌳🏙️\n- 'AgriculturalEncroachmentImpact': The product of agricultural practices and encroachments, representing the impact of agricultural encroachments. 🚜\n- 'DamDrainageInteraction': The product of dam quality and drainage systems, indicating the interaction between dams and drainage. 🏰🚰\n- 'LandslideSiltationInteraction': The product of landslides and siltation, representing the interaction between landslides and siltation. ⛰️💧\n- 'WatershedWetlandRatio': The ratio of watersheds to wetland loss. 🌊🌿\n- 'PoliticalPreparednessInteraction': The product of political factors and ineffective disaster preparedness, indicating the interaction between politics and preparedness. 🏛️🚧\n- 'TopographyDrainageSiltation': The sum of topographic drainage and siltation. 🗺️💧\n- 'ClimateAnthropogenicInteraction': The product of climate impact and anthropogenic pressure, representing the interaction between climate and anthropogenic factors. 🌍🏭\n- 'InfrastructurePreventionInteraction': The product of infrastructure quality and preventive measures efficiency, indicating the interaction between infrastructure and prevention. 🏗️🚧\n- 'CoastalEcosystemInteraction': The product of total coastal vulnerability and ecosystem impact, representing the interaction between coastal areas and ecosystems. 🌊🌿\n\nThese new features are designed to capture various aspects and interactions that may influence the likelihood of floods, potentially improving the performance of the regression mode","metadata":{}},{"cell_type":"code","source":"df_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_FEATURES = df_test.columns\n\ndef add_features(df):\n    df['total'] = df[BASE_FEATURES].sum(axis=1)\n    df['mean'] = df[BASE_FEATURES].mean(axis=1)\n    df['std'] = df[BASE_FEATURES].std(axis=1)\n    df['max'] = df[BASE_FEATURES].max(axis=1)\n    df['min'] = df[BASE_FEATURES].min(axis=1)\n    df['median'] = df[BASE_FEATURES].median(axis=1)\n    df['ptp'] = df[BASE_FEATURES].values.ptp(axis=1)\n    df['q25'] = df[BASE_FEATURES].quantile(0.25, axis=1)\n    df['q75'] = df[BASE_FEATURES].quantile(0.75, axis=1)\n    \n    df['ClimateImpact'] = df['MonsoonIntensity'] + df['ClimateChange']\n    df['AnthropogenicPressure'] = df['Deforestation'] + df['Urbanization'] + df['AgriculturalPractices'] + df['Encroachments']\n    df['InfrastructureQuality'] = df['DamsQuality'] + df['DrainageSystems'] + df['DeterioratingInfrastructure']\n    df['CoastalVulnerabilityTotal'] = df['CoastalVulnerability'] + df['Landslides']\n    df['PreventiveMeasuresEfficiency'] = df['RiverManagement'] + df['IneffectiveDisasterPreparedness'] + df['InadequatePlanning']\n    df['EcosystemImpact'] = df['WetlandLoss'] + df['Watersheds']\n    df['SocioPoliticalContext'] = df['PopulationScore'] * df['PoliticalFactors']\n\n\n    df['FloodVulnerabilityIndex'] = (df['AnthropogenicPressure'] + df['InfrastructureQuality'] +\n                                     df['CoastalVulnerabilityTotal'] + df['PreventiveMeasuresEfficiency']) / 4\n    \n    df['PopulationDensityImpact'] = df['PopulationScore'] * (df['Urbanization'] + df['Encroachments'])\n    \n    df['DeforestationUrbanizationRatio'] = df['Deforestation'] / df['Urbanization']\n    \n    df['AgriculturalEncroachmentImpact'] = df['AgriculturalPractices'] * df['Encroachments']\n    \n    df['DamDrainageInteraction'] = df['DamsQuality'] * df['DrainageSystems']\n    \n    df['LandslideSiltationInteraction'] = df['Landslides'] * df['Siltation']\n    \n    df['WatershedWetlandRatio'] = df['Watersheds'] / df['WetlandLoss']\n    \n    df['PoliticalPreparednessInteraction'] = df['PoliticalFactors'] * df['IneffectiveDisasterPreparedness']\n    \n    \n    df['TopographyDrainageSiltation'] = df['TopographyDrainage'] + df['Siltation']\n    \n    df['ClimateAnthropogenicInteraction'] = df['ClimateImpact'] * df['AnthropogenicPressure']\n    \n    df['InfrastructurePreventionInteraction'] = df['InfrastructureQuality'] * df['PreventiveMeasuresEfficiency']\n    \n    df['CoastalEcosystemInteraction'] = df['CoastalVulnerabilityTotal'] * df['EcosystemImpact']\n\n    return df\n\ndf_train = add_features(df_train)\ndf_test = add_features(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Machine Learning\n### Preparation","metadata":{}},{"cell_type":"code","source":"target = 'FloodProbability'\nfeatures = [col for col in df_train.columns if col != target ]\n\nX = df_train[features]\ny = df_train[target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For machine learning\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import HistGradientBoostingRegressor,RandomForestRegressor,GradientBoostingRegressor,VotingRegressor\nfrom sklearn.model_selection import KFold\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"for column in X.columns:\n    X[column].replace([np.inf, -np.inf], np.nan, inplace = True)\n    mean = X[column].mean(skipna=True)\n    X[column].fillna(mean, inplace = True)\nX.isnull().any().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Selection\n# Multiple Linear Regression","metadata":{}},{"cell_type":"code","source":"lm = LinearRegression()\n\n# Fit the data(train the model) \nlm.fit(X, y) \n\n# Predict\ny_predicted = lm.predict(X)\n\n# Model evaluation\nr2 = r2_score(y, y_predicted) \n\n# printing values \nprint('Slope:' ,lm.coef_) \nprint('Intercept:', lm.intercept_) \nprint('R2 score: ', r2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"# Create XGBoost model\nxgb = XGBRegressor(booster = 'gbtree',\n                   max_depth = 10,\n                   num_leaves = 250,\n                   reg_alpha = 0.1,\n                   reg_lambda = 3.25,\n                   learning_rate = 0.01,\n                   n_estimators = 3000,\n                   subsample_for_bin= 165700, \n                   min_child_samples= 114, \n                   colsample_bytree= 0.9634,\n                   subsample= 0.9592, \n                   random_state = 0)\n\nn_splits = 5\n# Create a KFold cross-validator\nkf = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n\nscores = []\n# Perform K-Fold Cross-Validation\nfor train_index, val_index in kf.split(X):\n    X_train, X_valid = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_valid = y[train_index], y[val_index]\n    xgb.fit(X_train, y_train)\n    y_pred = xgb.predict(X_valid)\n    score = r2_score(y_valid, y_pred)\n    print(score)\n    scores.append(score)\n\n# Output the average R2 score across all folds\nprint(f'Mean R2 score: {np.mean(scores):.5f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CatBoost Regressor","metadata":{}},{"cell_type":"code","source":"# Create CatBoostRegressor model\ncatb = CatBoostRegressor(n_estimators = 3000,\n                       learning_rate = 0.05,\n                       verbose = 0)\n\nn_splits = 5\n# Create a KFold cross-validator\nkf = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n\nscores = []\n# Perform K-Fold Cross-Validation\nfor train_index, val_index in kf.split(X):\n    X_train, X_valid = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_valid = y[train_index], y[val_index]\n    catb.fit(X_train, y_train)\n    y_pred = catb.predict(X_valid)\n    score = r2_score(y_valid, y_pred)\n    print(score)\n    scores.append(score)\n\n# Output the average R2 score across all folds\nprint(f'Mean R2 score: {np.mean(scores):.5f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"'''n_splits = 5\n# Create a KFold cross-validator\nkf = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n# Create XGBoost model\nlgbm = LGBMRegressor(objective = 'regression',\n               boosting_type = 'gbdt',\n               max_depth = 10,\n               num_leaves = 250,\n               reg_alpha = 0.1,\n               reg_lambda = 3.25,\n               learning_rate = 0.01,\n               n_estimators = 3000,\n               subsample_for_bin= 165700, \n               min_child_samples= 114, \n               colsample_bytree= 0.9634,\n               subsample= 0.9592, \n               random_state = 0,\n               verbosity = -1)\nscores = []\n# Perform K-Fold Cross-Validation\nfor train_index, val_index in kf.split(X):\n    X_train, X_valid = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_valid = y[train_index], y[val_index]\n    lgbm.fit(X_train, y_train)\n    y_pred = lgbm.predict(X_valid)\n    score = r2_score(y_valid, y_pred)\n    print(score)\n    scores.append(score)\n\n# Output the average R2 score across all folds\nprint(f'Mean R2 score: {np.mean(scores):.5f}')'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking Ensemble\nUse StackingCVRegressor to apply multiple regression methods to yield high accuracy and stability!","metadata":{}},{"cell_type":"code","source":"'''r1 = catb\nr2 = xgb\nr3 = lgbm\nr4 = lm\nr5 = HistGradientBoostingRegressor(learning_rate = 0.05,\n                                   max_iter = 400)\nr6 = GradientBoostingRegressor(learning_rate = 0.05,\n                               n_estimators = 400)\nr7 = RandomForestRegressor(n_estimators = 400,\n                           max_depth = 4)\nr8 = SVR(kernel='linear')\n\nstack = StackingCVRegressor(regressors=(r1, r2, r4, r5, r6, r7, r8),\n                            meta_regressor = CatBoostRegressor(verbose = 0),\n                            cv = KFold(n_splits=5))'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''stack.fit(X, y)'''","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''r1 = CatBoostRegressor(n_estimators = 1000,\n                       learning_rate = 0.05,\n                       verbose = 0)\nr2 = xgb\nr3 = lgb\nr4 = HistGradientBoostingRegressor(learning_rate = 0.05,\n                                   max_iter = 400)\nr5 = GradientBoostingRegressor(learning_rate = 0.05,\n                               n_estimators = 400)\nr6 = RandomForestRegressor(n_estimators = 400,\n                           max_depth = 4)\nr7 = LinearRegression()\nr8 = SVR(kernel='linear')\n\nstack = StackingCVRegressor(regressors=(r1, r2, r3, r4,r5,r6,r7,r8),\n                            meta_regressor = CatBoostRegressor(verbose = 0),\n                            cv = KFold(n_splits=10))'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r1 = catb\nr2 = xgb\n#r3 = lgbm\nr4 = HistGradientBoostingRegressor(learning_rate = 0.05,\n                                   max_iter = 400)\nr5 = GradientBoostingRegressor(learning_rate = 0.05,\n                               n_estimators = 400)\nr6 = RandomForestRegressor(n_estimators = 400,\n                           max_depth = 4)\nr7 = LinearRegression()\nr8 = SVR(kernel='linear')\n\nstack = StackingCVRegressor(regressors=(r1, r2, r4, r5, r6, r7, r8),\n                            meta_regressor = CatBoostRegressor(verbose = 0),\n                            cv = KFold(n_splits=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''n_splits = 5\n# Create a KFold cross-validator\nkf = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n\nscores = []\n# Perform K-Fold Cross-Validation\nfor train_index, val_index in kf.split(X):\n    X_train, X_valid = X.iloc[train_index], X.iloc[val_index]\n    y_train, y_valid = y[train_index], y[val_index]\n    stack.fit(X_train, y_train)\n    y_pred = stack.predict(X_valid)\n    score = r2_score(y_valid, y_pred)\n    print(score)\n    scores.append(score)\n\n# Output the average R2 score across all folds\nprint(f'Mean R2 score: {np.mean(scores):.5f}')'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stack.fit(X, y)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''for clf, label in zip([r1, r2, r3, r4,r5,r6,r7,r8, stack], ['CatBoostRegressor', 'XGBRegressor', \n                                                        'LGBMRegressor', 'HistGradientBoostingRegressor',\n                                                         'GradientBoostingRegressor','RandomForestRegressor','LinearRegression',\n                                                            'SVR','StackingCVRegressor']):\n    clf.fit(X, y)\n    scores = cross_val_score(clf, X, y, cv=2, scoring='r2')\n    print(\"R2 Score: %0.2f (+/- %0.2f) [%s]\" % (\n        scores.mean(), scores.std(), label))'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"X_submission = df_test[features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''y_xgb_pred = xgb.predict(X_submission)\n#y_lgb_pred = lgbm.predict(X_submission)\ny_cat_pred = catb.predict(X_submission)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''y_submission_pred = 0.5*y_xgb_pred + 0.5*y_cat_pred'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_submission_pred = stack.predict(X_submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.reset_index(inplace = True)\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"id\": df_test[\"id\"],\n    \"probability\": y_submission_pred,\n}).set_index('id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"./submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}